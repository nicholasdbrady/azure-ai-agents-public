{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODOs\n",
    "\n",
    "- [x] take an Excel file and convert it to markdown \n",
    "- [  ] then upload to the service \n",
    "- [  ] to use File Search\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Sales Analyst Agent**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **About the Scenario**\n",
    "This notebook demonstrates a practical use case where an AI Agent is leveraged to gain actionable insights and address key analytical questions related to AdventureWorks sales analysis. It combines file search, computation, and data visualization to streamline decision-making.\n",
    "\n",
    "The scenario utilizes an AI Agent integrated with two powerful tools: *File Search* and *Code Interpreter*. These tools work together to retrieve sales data from within an Excel Workbook and calculate sales metrics, replicating real-world workflows in retail sales.\n",
    "\n",
    "### Key Steps:\n",
    "1. *File Conversion*: Convert Excel Workboot into Markdown tables.\n",
    "2. *Upload Data*:Import a Markdown file containing the tables into the OpenAI Project.\n",
    "3. *Perform Sales Analysis*: Leverage *File Search* and *Code Interpreter to compute key sales metrics and insights.\n",
    "4. *Generate Report*: Leverage *Code Interpreter* to generate sales insights visualizations and leverage Python libraries to render a report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data**\n",
    "This scenario uses files from the folder [`data/`](./data/) in this repo. You can clone this repo or copy this folder to make sure you have access to these files when running the sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Time**\n",
    "You should expect to spend 10-15 minutes building and running this scenario. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Before you begin**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Install required libraries\n",
    "Install dependencies directly within a Jupyter notebook is a good practice because it ensures that all required packages are installed in the correct versions, making the notebook self-contained and reproducible. This approach helps other users or collaborators to set up the environment quickly and avoid potential issues related to missing or incompatible packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: azure-ai-projects==1.0.0b1 in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from -r ./requirements.txt (line 1)) (1.0.0b1)\n",
      "Requirement already satisfied: azure-identity==1.19.0 in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from -r ./requirements.txt (line 2)) (1.19.0)\n",
      "Requirement already satisfied: openpyxl==3.1.5 in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from -r ./requirements.txt (line 3)) (3.1.5)\n",
      "Requirement already satisfied: openai==1.55.0 in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from -r ./requirements.txt (line 4)) (1.55.0)\n",
      "Requirement already satisfied: pandas==2.2.3 in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from -r ./requirements.txt (line 5)) (2.2.3)\n",
      "Requirement already satisfied: python-dotenv==1.0.1 in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from -r ./requirements.txt (line 6)) (1.0.1)\n",
      "Requirement already satisfied: tabulate==0.9.0 in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from -r ./requirements.txt (line 7)) (0.9.0)\n",
      "Requirement already satisfied: isodate>=0.6.1 in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from azure-ai-projects==1.0.0b1->-r ./requirements.txt (line 1)) (0.7.2)\n",
      "Requirement already satisfied: azure-core>=1.30.0 in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from azure-ai-projects==1.0.0b1->-r ./requirements.txt (line 1)) (1.32.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from azure-ai-projects==1.0.0b1->-r ./requirements.txt (line 1)) (4.12.2)\n",
      "Requirement already satisfied: cryptography>=2.5 in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from azure-identity==1.19.0->-r ./requirements.txt (line 2)) (43.0.3)\n",
      "Requirement already satisfied: msal>=1.30.0 in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from azure-identity==1.19.0->-r ./requirements.txt (line 2)) (1.31.1)\n",
      "Requirement already satisfied: msal-extensions>=1.2.0 in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from azure-identity==1.19.0->-r ./requirements.txt (line 2)) (1.2.0)\n",
      "Requirement already satisfied: et-xmlfile in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from openpyxl==3.1.5->-r ./requirements.txt (line 3)) (2.0.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from openai==1.55.0->-r ./requirements.txt (line 4)) (4.6.2.post1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from openai==1.55.0->-r ./requirements.txt (line 4)) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from openai==1.55.0->-r ./requirements.txt (line 4)) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from openai==1.55.0->-r ./requirements.txt (line 4)) (0.7.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from openai==1.55.0->-r ./requirements.txt (line 4)) (2.9.2)\n",
      "Requirement already satisfied: sniffio in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from openai==1.55.0->-r ./requirements.txt (line 4)) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from openai==1.55.0->-r ./requirements.txt (line 4)) (4.67.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from pandas==2.2.3->-r ./requirements.txt (line 5)) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from pandas==2.2.3->-r ./requirements.txt (line 5)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from pandas==2.2.3->-r ./requirements.txt (line 5)) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from pandas==2.2.3->-r ./requirements.txt (line 5)) (2024.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai==1.55.0->-r ./requirements.txt (line 4)) (3.10)\n",
      "Requirement already satisfied: requests>=2.21.0 in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from azure-core>=1.30.0->azure-ai-projects==1.0.0b1->-r ./requirements.txt (line 1)) (2.32.3)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from azure-core>=1.30.0->azure-ai-projects==1.0.0b1->-r ./requirements.txt (line 1)) (1.16.0)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from cryptography>=2.5->azure-identity==1.19.0->-r ./requirements.txt (line 2)) (1.17.1)\n",
      "Requirement already satisfied: certifi in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai==1.55.0->-r ./requirements.txt (line 4)) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai==1.55.0->-r ./requirements.txt (line 4)) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.55.0->-r ./requirements.txt (line 4)) (0.14.0)\n",
      "Requirement already satisfied: PyJWT<3,>=1.0.0 in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from PyJWT[crypto]<3,>=1.0.0->msal>=1.30.0->azure-identity==1.19.0->-r ./requirements.txt (line 2)) (2.10.0)\n",
      "Requirement already satisfied: portalocker<3,>=1.4 in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from msal-extensions>=1.2.0->azure-identity==1.19.0->-r ./requirements.txt (line 2)) (2.10.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai==1.55.0->-r ./requirements.txt (line 4)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai==1.55.0->-r ./requirements.txt (line 4)) (2.23.4)\n",
      "Requirement already satisfied: colorama in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from tqdm>4->openai==1.55.0->-r ./requirements.txt (line 4)) (0.4.6)\n",
      "Requirement already satisfied: pycparser in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from cffi>=1.12->cryptography>=2.5->azure-identity==1.19.0->-r ./requirements.txt (line 2)) (2.22)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from portalocker<3,>=1.4->msal-extensions>=1.2.0->azure-identity==1.19.0->-r ./requirements.txt (line 2)) (308)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-ai-projects==1.0.0b1->-r ./requirements.txt (line 1)) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-ai-projects==1.0.0b1->-r ./requirements.txt (line 1)) (2.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Packages installed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Install the packages\n",
    "%pip install -r ./requirements.txt\n",
    "\n",
    "print(\"\\nPackages installed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Setting up the environment\n",
    "Before we begin, we need to load the necessary environment variables from a `.env` file. These variables include sensitive information such as API keys and endpoint URLs, which are crucial for running the code successfully.\n",
    "\n",
    "Here’s what you need to do:\n",
    "- Ensure your `.env` file is properly configured in the `.venv/.env` format. We have provided an template `.env` file, `.env.example` for your reference.\n",
    "- Verify that all required secrets are included in the file before running the code.\n",
    "\n",
    "\n",
    "The `.env` file must contain the following secrets:\n",
    "- PROJECT_CONNECTION_STRING: URL to connect to the Azure OpenAI Project to access project resources.\n",
    "- AZURE_OPENAI_DEPLOYMENT: The name of the Azure OpenAI model deployment.\n",
    "\n",
    "Now, let’s load these variables and get started!\n",
    "\n",
    "<code style=\"background:yellow;color:black\">Note: Make sure to keep your `.env` file secure and avoid sharing it publicly. </code>\n",
    "\n",
    "*For more information about leveraging Python Virtual Environments can be found [here](https://docs.python.org/3/library/venv.html).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve the secrets\n",
    "__PROJECT_CONNECTION_STRING = os.getenv(\"PROJECT_CONNECTION_STRING\")\n",
    "__AZURE_OPENAI_DEPLOYMENT = os.getenv(\"AZURE_OPENAI_DEPLOYMENT\")\n",
    "\n",
    "# Verify environment variables\n",
    "if not all([__PROJECT_CONNECTION_STRING, __AZURE_OPENAI_DEPLOYMENT]):\n",
    "    raise EnvironmentError(\"One or more environment variables are missing. Please check the .env file.\")\n",
    "else:\n",
    "    print(\"Environment variables loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Azure OpenAI Agent Setup**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Initializing the Azure Agent Runtime Client\n",
    "\n",
    "Next, we’ll initialize the Azure Agent Runtime client. This client allows us to interact with Azure OpenAI Project Agents. We will use a `DefaultAzureCredential` to authenticate, meaning you will have to be logged in with the Azure CLI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent client created successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "# Initialize the Azure AI Project client\n",
    "project_client = AIProjectClient.from_connection_string(\n",
    "    credential=DefaultAzureCredential(),\n",
    "    conn_str=os.environ[\"PROJECT_CONNECTION_STRING\"],\n",
    ")\n",
    "\n",
    "agent_client = project_client.agents\n",
    "\n",
    "print(\"Agent client created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Convert Excel workbook to Markdown files\n",
    "Currently, Microsoft Excel workbooks are not a supported file type for the *File Search* tool, therefore we must convert the Excel Workbook for this scenario into a compatible format, such as Markdown. This process converts each sheet in the Excel file to a Markdown table and saves them as separate Markdown files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workbook 'data\\SalesOrder_43659.xlsx' successfully loaded.\n",
      "Markdown file 'data\\uploads\\SalesOrder_43659.md' successfully written.\n",
      "Workbook 'data\\SalesOrder_43661.xlsx' successfully loaded.\n",
      "Markdown file 'data\\uploads\\SalesOrder_43661.md' successfully written.\n",
      "Workbook 'data\\SalesOrder_43662.xlsx' successfully loaded.\n",
      "Markdown file 'data\\uploads\\SalesOrder_43662.md' successfully written.\n",
      "Workbook 'data\\SalesOrder_43665.xlsx' successfully loaded.\n",
      "Markdown file 'data\\uploads\\SalesOrder_43665.md' successfully written.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define paths\n",
    "output_dir = \"uploads\"\n",
    "data_dir_path = \"data\"\n",
    "sales_order_files = [\"SalesOrder_43659.xlsx\", \"SalesOrder_43661.xlsx\", \"SalesOrder_43662.xlsx\", \"SalesOrder_43665.xlsx\"]\n",
    "\n",
    "output_dir_path = os.path.join(data_dir_path, output_dir)\n",
    "\n",
    "# Ensure output directory exists\n",
    "if not os.path.exists(output_dir_path):\n",
    "    os.makedirs(output_dir_path)\n",
    "\n",
    "# Prefix the data directory path to each file\n",
    "sales_order_files = [os.path.join(data_dir_path, curr_file) for curr_file in sales_order_files]\n",
    "\n",
    "# Store the uploaded file IDs to be used later when enabling File Search\n",
    "markdown_file_paths = []\n",
    "\n",
    "for curr_file in sales_order_files:\n",
    "    try:\n",
    "        # Check if the file exists\n",
    "        if not os.path.exists(curr_file):\n",
    "            raise FileNotFoundError(f\"The file '{curr_file}' does not exist.\")\n",
    "\n",
    "        # Load the Excel File into a DataFrame\n",
    "        df = pd.read_excel(curr_file)\n",
    "        print(f\"Workbook '{curr_file}' successfully loaded.\")\n",
    "\n",
    "        # Get the base name of the Excel file without the extension\n",
    "        base_name = os.path.splitext(os.path.basename(curr_file))[0]\n",
    "\n",
    "        # Convert the DataFrame to a Markdown table\n",
    "        md_tbl_str = df.to_markdown(index=False, tablefmt=\"pipe\")\n",
    "        \n",
    "        # Define the output file name\n",
    "        output_file = os.path.join(output_dir_path, f\"{base_name}.md\")\n",
    "        markdown_file_paths.append(output_file)\n",
    "        \n",
    "        # Write the Markdown table to the file\n",
    "        with open(output_file, \"w\") as f:\n",
    "            f.write(md_tbl_str)\n",
    "\n",
    "        print(f\"Markdown file '{output_file}' successfully written.\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing the Excel file '{curr_file}': {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Upload supporting file(s) to Azure OpenAI deployment\n",
    "Now, we'll upload the markdown files in the local directory that we created in the previous step to Azure OpenAI, ensuring any existing markdown files are removed beforehand to ensure the latest version of the files are used and no duplicates exist. This process handles the entire clean up and upload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing File 'data\\uploads\\SalesOrder_43659.md'...\n",
      "Uploaded file, file ID: assistant-gM5qUMC6FFWPUTVN5NtlZJNg\n",
      "Processing File 'data\\uploads\\SalesOrder_43661.md'...\n",
      "Uploaded file, file ID: assistant-IwBAmXH9WVOFVVK9pPgoBBUd\n",
      "Processing File 'data\\uploads\\SalesOrder_43662.md'...\n",
      "Uploaded file, file ID: assistant-JGvJYv0Z61vyFnX14NY3kw2g\n",
      "Processing File 'data\\uploads\\SalesOrder_43665.md'...\n",
      "Uploaded file, file ID: assistant-qPDd0TgBfynHLIFnAcke28UD\n",
      "File IDs: ['assistant-gM5qUMC6FFWPUTVN5NtlZJNg', 'assistant-IwBAmXH9WVOFVVK9pPgoBBUd', 'assistant-JGvJYv0Z61vyFnX14NY3kw2g', 'assistant-qPDd0TgBfynHLIFnAcke28UD']\n"
     ]
    }
   ],
   "source": [
    "uploaded_file_ids = []\n",
    "\n",
    "try:\n",
    "    for local_file in os.listdir(output_dir_path):\n",
    "\n",
    "        # Define the local file path\n",
    "        local_file_path = os.path.join(output_dir_path, local_file)\n",
    "\n",
    "        # Check if the file is a Markdown file\n",
    "        if not local_file.endswith(\".md\"):\n",
    "            continue\n",
    "        else:\n",
    "            print(f\"Processing File '{local_file_path}'...\")\n",
    "\n",
    "            # Check if the file already exists in the cloud, and delete it if it does\n",
    "            for cloud_file in agent_client.list_files().data:\n",
    "                if cloud_file.filename == local_file:\n",
    "                    agent_client.delete_file(cloud_file.id)\n",
    "                    print(f\"Deleted existing cloud file: '{cloud_file.filename}'\")\n",
    "\n",
    "            file = project_client.agents.upload_file_and_poll(file_path=local_file_path, purpose=\"assistants\")\n",
    "            uploaded_file_ids.append(file.id)\n",
    "            print(f\"Uploaded file, file ID: {file.id}\")\n",
    "            \n",
    "    print(f\"File IDs: {uploaded_file_ids}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{curr_file}' was not found.\")\n",
    "    raise\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while processing the Excel file: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Create Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store 'Sales Orders (vs_GH1bM1LM9HHHgLztrkatUPpT)' created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Create a vector store called \"Financial Statements\"\n",
    "vector_store = agent_client.create_vector_store_and_poll(file_ids=uploaded_file_ids, name=\"Sales Orders\")\n",
    "print(f\"Vector store '{vector_store.name} ({vector_store.id})' created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Create File Search Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.projects.models import FileSearchTool\n",
    "\n",
    "# Create file search tool with resources followed by creating agent\n",
    "file_search = FileSearchTool(vector_store_ids=[vector_store.id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Azure OpenAI Agent**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vector store gets created when file is uploaded and attached to the message tag as file_search from thread and conversation scope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Create a Sales Analyst Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent created successfully.\n",
      " asst_uyBZakeAFO7KBKG09dbH04BU\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    agent = project_client.agents.create_agent(\n",
    "        model=__AZURE_OPENAI_DEPLOYMENT,\n",
    "        name=\"Sales Analyst Agent\",\n",
    "        instructions=(\n",
    "            \"You are an expert sales analyst. \"\n",
    "            \"Use your knowledge base to answer questions about company sales, customers, and products.\"\n",
    "        ),\n",
    "        tools=file_search.definitions,\n",
    "        tool_resources=file_search.resources,\n",
    "    )\n",
    "    print(\"Agent created successfully.\\n\", agent.id)\n",
    "except Exception as e:\n",
    "    print(\"Error creating Agent:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Starting a New Converstaion Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread created successfully: thread_j6zRse2OYtU3cj27KVcUgXBl\n"
     ]
    }
   ],
   "source": [
    "# Create a conversation thread\n",
    "try:\n",
    "    thread = agent_client.create_thread()\n",
    "    print(\"Thread created successfully:\", thread.id)\n",
    "except Exception as e:\n",
    "    print(\"Error creating thread:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Adding User Message to the Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added User prompt to the thread.\n",
      " msg_WYimSo7E4ieMvD10IHpfHqIC\n"
     ]
    }
   ],
   "source": [
    "# Define the user question\n",
    "prompt_content = \"How much revenue did we generate in the last quarter by Reseller?\"\n",
    "\n",
    "# Add the question to the thread\n",
    "try:\n",
    "    message = agent_client.create_message(\n",
    "        thread_id=thread.id,\n",
    "        role=\"user\",\n",
    "        content=prompt_content,\n",
    "        #attachments=[{\"file_ids\": [file for file in uploaded_file_ids]}],\n",
    "    )\n",
    "    print(\"Successfully added User prompt to the thread.\\n\", message.id)\n",
    "except Exception as e:\n",
    "    print(\"Error adding user question:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Run Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run started: run_tQDWxRhaSpJ1C38vnr9LNnUe\n"
     ]
    }
   ],
   "source": [
    "# Initiate the Agent's response\n",
    "try:\n",
    "    run = agent_client.create_and_process_run(\n",
    "        thread_id=thread.id,\n",
    "        assistant_id=agent.id,\n",
    "        #instructions=prompt_content,\n",
    "    )\n",
    "    print(\"Run started:\", run.id)\n",
    "except Exception as e:\n",
    "    print(\"Error starting run:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run.status == \"failed\":\n",
    "    # Check if you got \"Rate limit is exceeded.\", then you want to get more quota\n",
    "    print(f\"Run failed: {run.last_error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Agent Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run completed!\n",
      "\n",
      "MESSAGES\n",
      "\n",
      "Assistant: The revenue generated in the last quarter by each reseller is as follows:\n",
      "\n",
      "1. **Original Bicycle Supply Company (Canada)**:\n",
      "   - Orders: Various products including HL Mountain Frame, Mountain-100 bikes, Sport-100 Helmet, Long-Sleeve Logo Jersey.\n",
      "   - Total Revenue: $38,750.72【4†source】【2†source】【5†source】【9†source】.\n",
      "\n",
      "2. **Better Bike Shop (United States, Southeast)**:\n",
      "   - Orders: Various products including Mountain-100 bikes, Sport-100 Helmet, AWC Logo Cap, Mountain Bike Socks.\n",
      "   - Total Revenue: $32,294.39【1†source】【6†source】【12†source】.\n",
      "\n",
      "3. **Latest Sports Equipment (United States, Northwest)**:\n",
      "   - Orders: Various products including Mountain-100 bikes, Sport-100 Helmet, Long-Sleeve Logo Jersey, AWC Logo Cap, Mountain Bike Socks.\n",
      "   - Total Revenue: $12,376.86【3†source】【4†source】【11†source】.\n",
      "\n",
      "4. **Health Spa, Limited (Canada)**:\n",
      "   - Orders: Various products including LL Road Frame, Road-650 bikes, ML Road Frame, Road-150 bikes.\n",
      "   - Total Revenue: $31,222.44【7†source】【8†source】【10†source】【13†source】【14†source】【15†source】.\n",
      "\n",
      "These figures represent the total revenue generated by each reseller for the last quarter based on the available sales order data.\n"
     ]
    }
   ],
   "source": [
    "messages = agent_client.list_messages(thread_id=thread.id, order=\"asc\", after=message.id)\n",
    "\n",
    "print(f'Run completed!\\n\\nMESSAGES\\n')\n",
    "\n",
    "# Loop through messages and print content based on role\n",
    "for msg in messages.data:\n",
    "    role = msg.role\n",
    "    content = msg.content[0].text.value\n",
    "    print(f\"{role.capitalize()}: {content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Clean Up**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Delete Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted vector store\n"
     ]
    }
   ],
   "source": [
    "project_client.agents.delete_vector_store(vector_store.id)\n",
    "print(\"Deleted vector store\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Delete Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted file: assistant-gM5qUMC6FFWPUTVN5NtlZJNg\n",
      "Deleted file: assistant-IwBAmXH9WVOFVVK9pPgoBBUd\n",
      "Deleted file: assistant-JGvJYv0Z61vyFnX14NY3kw2g\n",
      "Deleted file: assistant-qPDd0TgBfynHLIFnAcke28UD\n"
     ]
    }
   ],
   "source": [
    "# For each file id in the list, delete the file\n",
    "for file_id in uploaded_file_ids:\n",
    "    project_client.agents.delete_file(file_id)\n",
    "    print(f\"Deleted file: {file_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Delete Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted Agent Client\n",
      " {'id': 'asst_uyBZakeAFO7KBKG09dbH04BU', 'object': 'assistant.deleted', 'deleted': True}\n"
     ]
    }
   ],
   "source": [
    "# Get agent list\n",
    "agents = agent_client.list_agents()\n",
    "\n",
    "# If the agent exists in the list, delete it\n",
    "if agent.id in [a.id for a in agents.data]:\n",
    "    response = agent_client.delete_agent(agent.id)\n",
    "    print(\"Deleted Agent Client\\n\",response)\n",
    "else:\n",
    "    print(\"Agent does not exist to delete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
