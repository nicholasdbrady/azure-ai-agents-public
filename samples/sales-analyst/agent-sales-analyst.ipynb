{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Sales Analyst Agent**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **About the Scenario**\n",
    "In this scenario, we analyze sales data for AdventureWorks using Azure OpenAI. The AI agent performs tasks such as file retrieval, sales calculations, and generating insights by leveraging tools like File Search. This showcases how businesses can employ Azure OpenAI Agents to streamline analytical workflows and decision making.\n",
    "\n",
    "Key Steps:\n",
    "\n",
    "1. *File Conversion*: Converting Excel data into a Markdown format compatible with the AI agent.\n",
    "2. *File Upload*: Storing the converted files in the Azure OpenAI Project for efficient processing.\n",
    "3. *AI-Powered Analysis*: Leveraging Azure OpenAI to generate insights such as revenue metrics by region.\n",
    "\n",
    "This hands-on demonstration will prepare you to use Azure OpenAI Assistants for similar real-world data engineering and analytics tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data**\n",
    "This scenario uses files from the folder [`data/`](./data/) in this repo. You can clone this repo or copy this folder to make sure you have access to these files when running the sample.\n",
    "\n",
    "The sales data is stored in multiple Excel files located in the data/ directory. These files contain essential details to simulate sales orders, which the AI agent will analyze.\n",
    "\n",
    "Ensure you have the following files ready in the data/ directory:\n",
    "\n",
    "- SalesOrder_43659.xlsx\n",
    "- SalesOrder_43661.xlsx\n",
    "- SalesOrder_43662.xlsx\n",
    "- SalesOrder_43665.xlsx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Time**\n",
    "You should expect to spend 10-15 minutes building and running this scenario. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Before you begin**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Install required libraries\n",
    "Installing dependencies directly within a Jupyter notebook is a good practice because it ensures that all required packages are installed in the correct versions, making the notebook self-contained and reproducible. This approach helps other users or collaborators to set up the environment quickly and avoid potential issues related to missing or incompatible packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: azure-ai-projects==1.0.0b1 in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from -r ./requirements.txt (line 1)) (1.0.0b1)\n",
      "Requirement already satisfied: azure-identity==1.19.0 in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from -r ./requirements.txt (line 2)) (1.19.0)\n",
      "Requirement already satisfied: openpyxl==3.1.5 in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from -r ./requirements.txt (line 3)) (3.1.5)\n",
      "Requirement already satisfied: openai==1.55.0 in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from -r ./requirements.txt (line 4)) (1.55.0)\n",
      "Requirement already satisfied: pandas==2.2.3 in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from -r ./requirements.txt (line 5)) (2.2.3)\n",
      "Requirement already satisfied: python-dotenv==1.0.1 in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from -r ./requirements.txt (line 6)) (1.0.1)\n",
      "Requirement already satisfied: tabulate==0.9.0 in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from -r ./requirements.txt (line 7)) (0.9.0)\n",
      "Requirement already satisfied: isodate>=0.6.1 in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from azure-ai-projects==1.0.0b1->-r ./requirements.txt (line 1)) (0.7.2)\n",
      "Requirement already satisfied: azure-core>=1.30.0 in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from azure-ai-projects==1.0.0b1->-r ./requirements.txt (line 1)) (1.32.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from azure-ai-projects==1.0.0b1->-r ./requirements.txt (line 1)) (4.12.2)\n",
      "Requirement already satisfied: cryptography>=2.5 in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from azure-identity==1.19.0->-r ./requirements.txt (line 2)) (43.0.3)\n",
      "Requirement already satisfied: msal>=1.30.0 in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from azure-identity==1.19.0->-r ./requirements.txt (line 2)) (1.31.1)\n",
      "Requirement already satisfied: msal-extensions>=1.2.0 in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from azure-identity==1.19.0->-r ./requirements.txt (line 2)) (1.2.0)\n",
      "Requirement already satisfied: et-xmlfile in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from openpyxl==3.1.5->-r ./requirements.txt (line 3)) (2.0.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from openai==1.55.0->-r ./requirements.txt (line 4)) (4.6.2.post1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from openai==1.55.0->-r ./requirements.txt (line 4)) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from openai==1.55.0->-r ./requirements.txt (line 4)) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from openai==1.55.0->-r ./requirements.txt (line 4)) (0.7.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from openai==1.55.0->-r ./requirements.txt (line 4)) (2.9.2)\n",
      "Requirement already satisfied: sniffio in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from openai==1.55.0->-r ./requirements.txt (line 4)) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from openai==1.55.0->-r ./requirements.txt (line 4)) (4.67.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from pandas==2.2.3->-r ./requirements.txt (line 5)) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from pandas==2.2.3->-r ./requirements.txt (line 5)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from pandas==2.2.3->-r ./requirements.txt (line 5)) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from pandas==2.2.3->-r ./requirements.txt (line 5)) (2024.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai==1.55.0->-r ./requirements.txt (line 4)) (3.10)\n",
      "Requirement already satisfied: requests>=2.21.0 in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from azure-core>=1.30.0->azure-ai-projects==1.0.0b1->-r ./requirements.txt (line 1)) (2.32.3)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from azure-core>=1.30.0->azure-ai-projects==1.0.0b1->-r ./requirements.txt (line 1)) (1.16.0)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from cryptography>=2.5->azure-identity==1.19.0->-r ./requirements.txt (line 2)) (1.17.1)\n",
      "Requirement already satisfied: certifi in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai==1.55.0->-r ./requirements.txt (line 4)) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai==1.55.0->-r ./requirements.txt (line 4)) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.55.0->-r ./requirements.txt (line 4)) (0.14.0)\n",
      "Requirement already satisfied: PyJWT<3,>=1.0.0 in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from PyJWT[crypto]<3,>=1.0.0->msal>=1.30.0->azure-identity==1.19.0->-r ./requirements.txt (line 2)) (2.10.0)\n",
      "Requirement already satisfied: portalocker<3,>=1.4 in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from msal-extensions>=1.2.0->azure-identity==1.19.0->-r ./requirements.txt (line 2)) (2.10.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai==1.55.0->-r ./requirements.txt (line 4)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai==1.55.0->-r ./requirements.txt (line 4)) (2.23.4)\n",
      "Requirement already satisfied: colorama in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from tqdm>4->openai==1.55.0->-r ./requirements.txt (line 4)) (0.4.6)\n",
      "Requirement already satisfied: pycparser in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from cffi>=1.12->cryptography>=2.5->azure-identity==1.19.0->-r ./requirements.txt (line 2)) (2.22)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from portalocker<3,>=1.4->msal-extensions>=1.2.0->azure-identity==1.19.0->-r ./requirements.txt (line 2)) (308)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-ai-projects==1.0.0b1->-r ./requirements.txt (line 1)) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\developer\\repos\\github\\azure-ai-agents\\samples\\investment_advisor\\.venv\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-ai-projects==1.0.0b1->-r ./requirements.txt (line 1)) (2.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Packages installed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Install the packages\n",
    "%pip install -r ./requirements.txt\n",
    "\n",
    "print(\"\\nPackages installed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Setting up the environment\n",
    "Before we begin, we need to load the necessary environment variables from a `.env` file. These variables include sensitive information such as API keys and endpoint URLs, which are crucial for running the code successfully.\n",
    "\n",
    "Here’s what you need to do:\n",
    "- Ensure your `.env` file is properly configured in the `.venv/.env` format. We have provided an template `.env` file, `.env.example` for your reference.\n",
    "- Verify that all required secrets are included in the file before running the code.\n",
    "\n",
    "\n",
    "The `.env` file must contain the following secrets:\n",
    "- PROJECT_CONNECTION_STRING: URL to connect to the Azure OpenAI Project to access project resources.\n",
    "- AZURE_OPENAI_DEPLOYMENT: The name of the Azure OpenAI model deployment.\n",
    "\n",
    "Now, let’s load these variables and get started!\n",
    "\n",
    "<code style=\"background:yellow;color:black\">Note: Make sure to keep your `.env` file secure and avoid sharing it publicly. </code>\n",
    "\n",
    "*For more information about leveraging Python Virtual Environments can be found [here](https://docs.python.org/3/library/venv.html).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve the secrets\n",
    "__PROJECT_CONNECTION_STRING = os.getenv(\"PROJECT_CONNECTION_STRING\")\n",
    "__AZURE_OPENAI_DEPLOYMENT = os.getenv(\"AZURE_OPENAI_DEPLOYMENT\")\n",
    "\n",
    "# Verify environment variables\n",
    "if not all([__PROJECT_CONNECTION_STRING, __AZURE_OPENAI_DEPLOYMENT]):\n",
    "    raise EnvironmentError(\"One or more environment variables are missing. Please check the .env file.\")\n",
    "else:\n",
    "    print(\"Environment variables loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Azure OpenAI Agent Setup**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Initializing the Azure AI Studio Project Client\n",
    "First, we will initialize the Azure AI Studio Project client using Azure’s `DefaultAzureCredential` for authentication, allowing seamless integration with Azure resources. You will need to log into Azure using the Azure CLI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure AI Studio client created successfully.\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "try:\n",
    "    # Initialize the Azure AI Project client\n",
    "    project_client = AIProjectClient.from_connection_string(\n",
    "        credential=DefaultAzureCredential(),\n",
    "        conn_str=os.environ[\"PROJECT_CONNECTION_STRING\"],\n",
    "    )\n",
    "\n",
    "    print(\"Azure AI Studio client created successfully.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error creating the project client: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Initializing the Azure Agent Client\n",
    "Next, we’ll initialize the Azure Agent Runtime client. The Azure Agent Client serves as the interface to interact with Azure OpenAI services. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent Client created successfully.\n"
     ]
    }
   ],
   "source": [
    "agent_client = project_client.agents\n",
    "\n",
    "print(f\"Agent Client created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Processing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Convert Excel files to Markdown\n",
    "Azure OpenAI Agents require data in specific file formats for processing. Since Excel files aren’t natively supported, our files need to be converted to Markdown tables in separate Markdown files. This step involves:\n",
    "\n",
    "- Reading Excel files using pandas.\n",
    "- Writing the data into Markdown format for compatibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workbook 'data\\SalesOrder_43659.xlsx' successfully loaded.\n",
      "Markdown file 'data\\uploads\\SalesOrder_43659.md' successfully written.\n",
      "Workbook 'data\\SalesOrder_43661.xlsx' successfully loaded.\n",
      "Markdown file 'data\\uploads\\SalesOrder_43661.md' successfully written.\n",
      "Workbook 'data\\SalesOrder_43662.xlsx' successfully loaded.\n",
      "Markdown file 'data\\uploads\\SalesOrder_43662.md' successfully written.\n",
      "Workbook 'data\\SalesOrder_43665.xlsx' successfully loaded.\n",
      "Markdown file 'data\\uploads\\SalesOrder_43665.md' successfully written.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define paths\n",
    "output_dir = \"uploads\"\n",
    "data_dir_path = \"data\"\n",
    "sales_order_files = [\"SalesOrder_43659.xlsx\", \"SalesOrder_43661.xlsx\", \"SalesOrder_43662.xlsx\", \"SalesOrder_43665.xlsx\"]\n",
    "output_dir_path = os.path.join(data_dir_path, output_dir)\n",
    "\n",
    "# Ensure output directory exists\n",
    "if not os.path.exists(output_dir_path):\n",
    "    os.makedirs(output_dir_path)\n",
    "\n",
    "# Prefix the data directory path to each file\n",
    "sales_order_files = [os.path.join(data_dir_path, curr_file) for curr_file in sales_order_files]\n",
    "\n",
    "# Store the uploaded file IDs to be used later when enabling File Search\n",
    "markdown_file_paths = []\n",
    "\n",
    "for curr_file in sales_order_files:\n",
    "    try:\n",
    "        # Check if the file exists\n",
    "        if not os.path.exists(curr_file):\n",
    "            raise FileNotFoundError(f\"The file '{curr_file}' does not exist.\")\n",
    "\n",
    "        # Load the Excel File into a DataFrame\n",
    "        df = pd.read_excel(curr_file)\n",
    "        print(f\"Workbook '{curr_file}' successfully loaded.\")\n",
    "\n",
    "        # Get the base name of the Excel file without the extension\n",
    "        base_name = os.path.splitext(os.path.basename(curr_file))[0]\n",
    "\n",
    "        # Convert the DataFrame to a Markdown table\n",
    "        md_tbl_str = df.to_markdown(index=False, tablefmt=\"pipe\")\n",
    "        \n",
    "        # Define the output file name\n",
    "        output_file = os.path.join(output_dir_path, f\"{base_name}.md\")\n",
    "        markdown_file_paths.append(output_file)\n",
    "        \n",
    "        # Write the Markdown table to the file\n",
    "        with open(output_file, \"w\") as f:\n",
    "            f.write(md_tbl_str)\n",
    "\n",
    "        print(f\"Markdown file '{output_file}' successfully written.\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing the Excel file '{curr_file}': {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Upload Markdown file(s) to OpenAI\n",
    "Next, we'll upload the markdown files from the local directory, `data\\uploads`, to the Azure OpenAI Project Deployment. Before uploading, any markdown files in the project with the same name are removed to ensure the latest versions are used and to prevent duplicates. This step efficiently manages cleanup and file upload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing File 'data\\uploads\\SalesOrder_43659.md'...\n",
      "Uploaded file, file ID: assistant-O3dFrHM7oB1mk2smKTPWxClj\n",
      "Processing File 'data\\uploads\\SalesOrder_43661.md'...\n",
      "Uploaded file, file ID: assistant-DiZoErgBYqeiCxIfLdn150g4\n",
      "Processing File 'data\\uploads\\SalesOrder_43662.md'...\n",
      "Uploaded file, file ID: assistant-krFHS2VtztRMgiKyQfpiFE6m\n",
      "Processing File 'data\\uploads\\SalesOrder_43665.md'...\n",
      "Uploaded file, file ID: assistant-8w5qzuilkXjGt6ro4tthg9Oo\n",
      "File IDs: ['assistant-O3dFrHM7oB1mk2smKTPWxClj', 'assistant-DiZoErgBYqeiCxIfLdn150g4', 'assistant-krFHS2VtztRMgiKyQfpiFE6m', 'assistant-8w5qzuilkXjGt6ro4tthg9Oo']\n"
     ]
    }
   ],
   "source": [
    "uploaded_file_ids = []\n",
    "\n",
    "try:\n",
    "    for local_file in os.listdir(output_dir_path):\n",
    "\n",
    "        # Define the local file path\n",
    "        local_file_path = os.path.join(output_dir_path, local_file)\n",
    "\n",
    "        # Check if the file is a Markdown file\n",
    "        if not local_file.endswith(\".md\"):\n",
    "            continue\n",
    "        else:\n",
    "            print(f\"Processing File '{local_file_path}'...\")\n",
    "\n",
    "            # Check if the file already exists in the cloud, and delete it if it does\n",
    "            for cloud_file in agent_client.list_files().data:\n",
    "                if cloud_file.filename == local_file:\n",
    "                    agent_client.delete_file(cloud_file.id)\n",
    "                    print(f\"Deleted existing cloud file: '{cloud_file.filename}'\")\n",
    "\n",
    "            # Use the upload and poll SDK helper to upload the local file, add them to the vector store,\n",
    "            # and poll the status of the file batch for completion.\n",
    "            file = project_client.agents.upload_file_and_poll(file_path=local_file_path, purpose=\"assistants\")\n",
    "            uploaded_file_ids.append(file.id)\n",
    "            print(f\"Uploaded file, file ID: {file.id}\")\n",
    "            \n",
    "    print(f\"File IDs: {uploaded_file_ids}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{curr_file}' was not found.\")\n",
    "    raise\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while processing the Excel file: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Create Vector Store\n",
    "The Vector Store is used to store embeddings of uploaded files, enabling the File Search tool to efficiently locate relevant content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store 'Sales Orders (vs_7OKcYpVcByFxhDrvG3os2H1q)' created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Create a vector store called \"Financial Statements\"\n",
    "vector_store = agent_client.create_vector_store_and_poll(file_ids=uploaded_file_ids, name=\"Sales Orders\")\n",
    "print(f\"Vector store '{vector_store.name} ({vector_store.id})' created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Create File Search Tool\n",
    "The File Search tool enables the AI agent to query the uploaded files. It uses the embeddings stored in the Vector Store to locate and retrieve relevant content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File search tool created successfully for Vector Store Sales Orders (vs_7OKcYpVcByFxhDrvG3os2H1q).\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.projects.models import FileSearchTool\n",
    "\n",
    "# Create file search tool with resources followed by creating agent\n",
    "file_search = FileSearchTool(vector_store_ids=[vector_store.id])\n",
    "print(f\"File search tool created successfully for Vector Store {vector_store.name} ({vector_store.id}).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Running the Azure OpenAI Agent**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Create a Sales Analyst Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent created successfully.(asst_Inw87xkNhy0XXpbzKK0byckR)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    agent = project_client.agents.create_agent(\n",
    "        model=__AZURE_OPENAI_DEPLOYMENT,\n",
    "        name=\"Sales Analyst Agent\",\n",
    "        instructions=(\n",
    "            \"You are an expert sales analyst. \"\n",
    "            \"Use your knowledge base to answer questions about company sales, customers, and products.\"\n",
    "        ),\n",
    "        tools=file_search.definitions,\n",
    "        tool_resources=file_search.resources,\n",
    "    )\n",
    "    print(f\"Agent created successfully.({agent.id})\")\n",
    "except Exception as e:\n",
    "    print(\"Error creating Agent:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Start a New Converstaion\n",
    "Conversation threads in Azure OpenAI enable context-aware interactions, storing both user prompts and agent responses. This step creates a new thread for the Sales Analyst Agent to handle queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread created successfully (thread_hoaC41o50uS0LpfvUkwsPTMk)\n"
     ]
    }
   ],
   "source": [
    "# Create a conversation thread\n",
    "try:\n",
    "    thread = agent_client.create_thread()\n",
    "    print(f\"Thread created successfully ({thread.id})\")\n",
    "except Exception as e:\n",
    "    print(\"Error creating thread:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Query the AI Agent\n",
    "Next, we’ll add a user message to the thread. The AI agent responds to a user-defined prompt, such as calculating revenue by region. It processes the prompt and retrieves the necessary data to deliver insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added User prompt to the thread. (Message ID msg_IROdK8ioDswCMKg1qX0N0lfw)\n"
     ]
    }
   ],
   "source": [
    "# Define the user question\n",
    "prompt_content = \"How much revenue did we generate by Region and what is the percentage of revenue generated by each region?\"\n",
    "\n",
    "# Add the question to the thread\n",
    "try:\n",
    "    message = agent_client.create_message(\n",
    "        thread_id=thread.id,\n",
    "        role=\"user\",\n",
    "        content=prompt_content,\n",
    "    )\n",
    "    print(f\"Successfully added User prompt to the thread. (Message ID {message.id})\")\n",
    "except Exception as e:\n",
    "    print(\"Error adding user question:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Run the AI Agent\n",
    "In this step, we instruct the AI agent to process the user’s query within the created thread. The agent analyzes the context, executes the required tools (e.g., File Search), and generates a response. The `create_and_proces_run` function triggers the agent to process the user's prompt and produce an agent output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run started: run_RfPzZGy2AjOenDHZunMijlGF\n"
     ]
    }
   ],
   "source": [
    "# Initiate the Agent's response\n",
    "try:\n",
    "    run = agent_client.create_and_process_run(\n",
    "        thread_id=thread.id,\n",
    "        assistant_id=agent.id,\n",
    "    )\n",
    "    print(\"Run started:\", run.id)\n",
    "except Exception as e:\n",
    "    print(\"Error starting run:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the agent run fails, we will identify the issue. A common cause is exceeding the rate limit, requiring additional Azure quotas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run.status == \"failed\":\n",
    "    # Check if you got \"Rate limit is exceeded.\", then you want to get more quota\n",
    "    print(f\"Run failed: {run.last_error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Extract Insights\n",
    "After the agent processes the prompt, we retrieve its responses, which contain the requested insights. This step ensures that the conversation thread is queried to fetch all relevant messages generated during the interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run completed!\n",
      "\n",
      "MESSAGES\n",
      "\n",
      "Assistant: To determine the revenue generated by region and the percentage of total revenue for each region, I reviewed the sales data provided. Here is the summary:\n",
      "\n",
      "### Revenue by Region\n",
      "- **Canada**: $73,748.00\n",
      "- **United States - Southeast**: $37,298.43\n",
      "- **United States - Northwest**: $26,709.85\n",
      "\n",
      "### Total Revenue\n",
      "- **Total Revenue**: $137,756.28\n",
      "\n",
      "### Percentage of Revenue by Region\n",
      "- **Canada**: (73,748.00 / 137,756.28) * 100 ≈ 53.55%\n",
      "- **United States - Southeast**: (37,298.43 / 137,756.28) * 100 ≈ 27.07%\n",
      "- **United States - Northwest**: (26,709.85 / 137,756.28) * 100 ≈ 19.39%\n",
      "\n",
      "#### Detailed Breakdown:\n",
      "1. **Canada Sales**\n",
      "   - Total: $73,748.00\n",
      "2. **United States - Southeast Sales**\n",
      "   - Total: $37,298.43\n",
      "3. **United States - Northwest Sales**\n",
      "   - Total: $26,709.85\n",
      "\n",
      "These calculations are based on aggregated figures from highlighted sales data such as:\n",
      "\n",
      "- **Canada Examples**\n",
      "  - Order SO43661 with items totaling $31,204.78【4:0†source】.\n",
      "  - Order SO43662 with items totaling $42,543.22【4:3†source】.\n",
      "\n",
      "- **United States - Southeast Examples**\n",
      "  - Order SO43659 with items totaling $37,298.43【4:1†source】【4:11†source】.\n",
      "\n",
      "- **United States - Northwest Examples**\n",
      "  - Order SO43665 with items totaling $26,709.85【4:2†source】【4:7†source】.\n",
      "\n",
      "These orders and their respective sales amounts are sampled and aggregated to provide the total revenue and respective percentages by region. The precise values and detailed transactions are available in the provided sales data files.\n"
     ]
    }
   ],
   "source": [
    "# Retrieves all messages from the thread in ascending order after the user message\n",
    "messages = agent_client.list_messages(thread_id=thread.id, order=\"asc\", after=message.id)\n",
    "\n",
    "print(f'Run completed!\\n\\nMESSAGES\\n')\n",
    "\n",
    "# Loop through messages and print content based on role\n",
    "for msg in messages.data:\n",
    "    role = msg.role\n",
    "    content = msg.content[0].text.value\n",
    "    print(f\"{role.capitalize()}: {content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Clean Up**\n",
    "\n",
    "Properly cleaning up Azure resources after completing the analysis is essential to maintain a tidy Azure AI Studio Project environment and to avoid incurring unnecessary costs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Deleting the Vector Store\n",
    "Remove the Vector Store to free up storage resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted vector store\n"
     ]
    }
   ],
   "source": [
    "project_client.agents.delete_vector_store(vector_store.id)\n",
    "print(\"Deleted vector store\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Deleting Uploaded Files\n",
    "Ensure all uploaded files are removed from Azure to maintain a clean environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted file: assistant-O3dFrHM7oB1mk2smKTPWxClj\n",
      "Deleted file: assistant-DiZoErgBYqeiCxIfLdn150g4\n",
      "Deleted file: assistant-krFHS2VtztRMgiKyQfpiFE6m\n",
      "Deleted file: assistant-8w5qzuilkXjGt6ro4tthg9Oo\n"
     ]
    }
   ],
   "source": [
    "# For each file id in the list, delete the file\n",
    "for file_id in uploaded_file_ids:\n",
    "    project_client.agents.delete_file(file_id)\n",
    "    print(f\"Deleted file: {file_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Deleting the AI Agent\n",
    "Remove the AI Agent to release associated resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted Agent Client\n",
      " {'id': 'asst_Inw87xkNhy0XXpbzKK0byckR', 'object': 'assistant.deleted', 'deleted': True}\n"
     ]
    }
   ],
   "source": [
    "# Get agent list\n",
    "agents = agent_client.list_agents()\n",
    "\n",
    "# If the agent exists in the list, delete it\n",
    "if agent.id in [a.id for a in agents.data]:\n",
    "    response = agent_client.delete_agent(agent.id)\n",
    "    print(\"Deleted Agent Client\\n\",response)\n",
    "else:\n",
    "    print(\"Agent does not exist to delete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Deleting local Markdown files\n",
    "Remove the local Markdown files generated during this scenario to maintain a clean local environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted local markdown file: data\\uploads\\SalesOrder_43659.md\n",
      "Deleted local markdown file: data\\uploads\\SalesOrder_43661.md\n",
      "Deleted local markdown file: data\\uploads\\SalesOrder_43662.md\n",
      "Deleted local markdown file: data\\uploads\\SalesOrder_43665.md\n"
     ]
    }
   ],
   "source": [
    "# Delete all local markdown files from the output directory\n",
    "for file_path in markdown_file_paths:\n",
    "    os.remove(file_path)\n",
    "    print(f\"Deleted local markdown file: {file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
